{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "810cb733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e4e826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ResNet50 loaded for Grad-CAM\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n",
    "\n",
    "# We will use the LAST convolutional layer\n",
    "target_layer = resnet.layer4[-1]\n",
    "\n",
    "print(\"✓ ResNet50 loaded for Grad-CAM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01614d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01382369",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "\n",
    "        self._register_hooks()\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output.detach()\n",
    "\n",
    "        def backward_hook(module, grad_in, grad_out):\n",
    "            self.gradients = grad_out[0].detach()\n",
    "\n",
    "        self.target_layer.register_forward_hook(forward_hook)\n",
    "        self.target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "    def generate(self, input_tensor, class_idx=None):\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        output = self.model(input_tensor)\n",
    "\n",
    "        # Since it's regression-like usage, take mean activation\n",
    "        score = output.mean()\n",
    "        score.backward()\n",
    "\n",
    "        weights = self.gradients.mean(dim=(2, 3), keepdim=True)\n",
    "        cam = (weights * self.activations).sum(dim=1)\n",
    "\n",
    "        cam = F.relu(cam)\n",
    "        cam = cam.squeeze().cpu().numpy()\n",
    "\n",
    "        cam = cv2.resize(cam, (224, 224))\n",
    "        cam = (cam - cam.min()) / (cam.max() + 1e-8)\n",
    "\n",
    "        return cam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc4d0f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually select representative property IDs\n",
    "sample_property_ids = [\n",
    "    7129300520,  # example high-value\n",
    "    6414100192,  # urban\n",
    "    1925069082,  # suburban\n",
    "    3655000070,  # greenery\n",
    "    1180000207,  # dense area\n",
    "    8562750320   # random\n",
    "]\n",
    "\n",
    "image_dir = 'data/images/train'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3baa4326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/Documents/Cursor Projects/CDC /satellite-property-valuation/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1866: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved Grad-CAM for property 3885802970\n",
      "✓ Saved Grad-CAM for property 5318101040\n",
      "✓ Saved Grad-CAM for property 7885800160\n",
      "✓ Saved Grad-CAM for property 5608000860\n",
      "✓ Saved Grad-CAM for property 7169500020\n",
      "✓ Saved Grad-CAM for property 1442300035\n"
     ]
    }
   ],
   "source": [
    "def find_image_path(image_dir, prop_id):\n",
    "    for ext in ['.png', '.jpg', '.jpeg']:\n",
    "        path = os.path.join(image_dir, f\"{prop_id}{ext}\")\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "    return None\n",
    "\n",
    "\n",
    "image_dir = '../data/images/train'\n",
    "os.makedirs('../outputs/cam_visualizations', exist_ok=True)\n",
    "\n",
    "available_ids = [\n",
    "    int(os.path.splitext(f)[0])\n",
    "    for f in os.listdir(image_dir)\n",
    "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "]\n",
    "\n",
    "sample_property_ids = available_ids[:6]\n",
    "\n",
    "gradcam = GradCAM(resnet, target_layer)\n",
    "\n",
    "for prop_id in sample_property_ids:\n",
    "    img_path = find_image_path(image_dir, prop_id)\n",
    "\n",
    "    if img_path is None:\n",
    "        continue\n",
    "\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_tensor = image_transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    cam = gradcam.generate(img_tensor)\n",
    "\n",
    "    img_np = np.array(img.resize((224, 224)))\n",
    "    heatmap = cv2.applyColorMap(\n",
    "        np.uint8(255 * cam),\n",
    "        cv2.COLORMAP_JET\n",
    "    )\n",
    "\n",
    "    overlay = cv2.addWeighted(img_np, 0.6, heatmap, 0.4, 0)\n",
    "\n",
    "    out_path = f'../outputs/cam_visualizations/{prop_id}_gradcam.png'\n",
    "    cv2.imwrite(out_path, cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    print(f\"✓ Saved Grad-CAM for property {prop_id}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
